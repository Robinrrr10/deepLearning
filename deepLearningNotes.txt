Deep Learning Notes:
--------------------
--------------------
--------------------

Below is the tutorial link which we are using for learning deep learning
Youtube playlist link: 
https://www.youtube.com/playlist?list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO





Tutorial 1: Introduction | Deep Learning Tutorial 1 (Tensorflow Tutorial, Keras & Python)
------------------------------------------------------------------------------------------
This is intro of the video.
In this whole course we will learning about deep learning.
Its for beginner.
The pre-request for the course is, you should know the python, basics of pandas and machine learning
Here we will use tensor flow, keras and python.
  
--------------------------------------------------------------------

Tutorial 2: Why deep learning is becoming so popular? | Deep Learning Tutorial 2 (Tensorflow2.0, Keras & Python)
-----------------------------------------------------------------------------------------------------------------
Deep learning is popular and started using because of below 4 reasons

1. Data growth : 
In most of the recent years, there are more data growth (for each company or in social media or in any other). So companies wanted to use that data for further growth by processing something

2. Hardware advancement:
Olden days we have limitation in hardware to run deep learning or with huge data. Our computer don't support or takes hours of time for execution of any thing related to deep learning.
Now there are GPU's and TPU's available which we can use for deep learning or processing huge data.

3. Python and Open source ecosystem:
Previously the deep learning is done on few places. That too in C++.
Now we have python which will be easy that C++ and Java.
Also deep learning libraries become free and open source now.
Tensorflow is one of deep learning framework made by google. It is now open source
Pytorch is also one of the deep learning framework made by facebook. It is also now open source.
So now using any of these framework, things becomes easy for deep learning

4. Cloud and AI boom
Now there is cloud, which also support to run the deep learnings on the cloud machine.
Also few tech companies also annonced that many of their techs are replaced with AI.
So the AI also boom and many companies started with the AI.


All these 4 reason made the deep learning so popular.

---------------------------------------------------------------------------------------

Tutorial 3: What is a neuron? | Deep Learning Tutorial 3 (Tensorflow Tutorial, Keras & Python)
----------------------------------------------------------------------------------------------
Neuron is the technique where we will use two different way(steps) sequenctly to predict the right value. 
First function result will be passed to next function/equation to have the right result
Second function/equation is called activation function
Eg:
First way is the linear logistic classification, then the result and the value will be passed to sigmoid function(equation). 
So the prediction will be accurate

Eg:
First function (Eg: Linear) ----> Second function(Sigmoid) => Result

Simoid is the equation which gives any one of the two result. 0 or 1.
If result is greater than 0.5, it will be 1
If result is less than 0.5, it will be 0

Lets take an example of insurance data which has two columns 1. age and 2. hasInsurance
Here if we plot that in scatter plot chat with age on x axis and has insurance on y axis.
This will show that nearly before 42 they dont have insurace, post 42 they have the insurance
We can use linear logistic regression to draw a line which split whether person has insurace or not.
Regarding linear logistic regression, we can refer our machine learning tutorial 8 and 9 (https://github.com/Robinrrr10/machineLearning/tree/main/tutorial8_logistic_regression_or_classification, https://github.com/Robinrrr10/machineLearning/tree/main/tutorial8_part_2_logistic_regression_and_multiclass_classification_with_example_of_number_image_prediction)
By using that line we can differentiate.
But lets say the data point has few data where more aged person has the insurance.
In that case, the line might go little bad and move towards 45 age as the split and the it might miss to predict the correct one.
When missed, even for age 43, 44 it will predict they don't have insurance which is wrong.
This is the problem with linear regression (straight line).
Then to solve this, with that value, we are drawing the curved line kind of the S
Which split these two in better way.
That curved approach is called sigmoid o logit function. 
There is a equation for this.
This uses the result of previous linear result into this the sigmoid to make that better.

Below is the formula for sigmoid

Formula
z = sigmoid(y)
sigmoid(y) = 1/1+e^-y                     //Here e is Euler's number ~ 2.71828
z =  1/1+e^-y

Example:
sigmoid(200) = 1/1+2.71^-200           => Almost close to 1

sigmoid(-200) = 1/1+2.71^200           => Almost close to 0

sigmoid will give the result in the range of 0 to 1.
If it is close to 0, we need to go with 0
If it is close to 1, we need to go with 1
Here 0.5 splits whether it is close to 0 or close to 1

Here we have 2 steps.
In first step, we are still drawing with linear equaltion
y = mx + b         //x is age

In second step, we are using y which we got from previous step in sigmoid equation below
z = 1/1+e^-y        //z is is person will buy insurance

In first step we are using linear logistics classification and drawing straight line and finding y.
In second step, we are using the y on sigmoid formula and finding the z whether the person will buy insurance or not


Lets say from the linear logistics regression we are getting below. We can get value via model.coef_ and model.intercept_

y = 0.042 * x + 1.53   //x is age,   0.042 is the m (model.coef_) and 1.53 is the b (model.intercept_) //This same we get from ml tutorial 8 of the video

Here when x age is passed, it will give y and that y will be given on below sigmoid formula

z = 1/1+e^-y               //e is 2.71 constant. y we get from above

And we will get z

as per example if age 35 is passed we will get 0.48 which is less than 0.5, so near to 0. So person wont buy insurance

as per example if age 43 is passed we will get 0.57 which is more than 0.5, so near to 1. So person will buy insurance

In this case step 1 and step 2 are involed for logistics regression. This is neuron
So here first it will use linear mode(linear logistics regression) and then the value is passed to activate function (sigmoid) this is neuron



In above example, we have taken only one feature which is the age, for this above is the equation
y = 0.042 * x + 1.53   //x is age,

There can be multiple features for the prediction, in that case, we need to use below formula

y = 0.042 * X1 +  0.008 * X2 +  0.2 * X3 + 1.53  //where X1 is age, X2 is income, X3 is education

y = W1 * X1 +  W2 * X2 +  W3 * X3 + b   //Equation

y = nEn=1 W^iX^i + b  //Please refer image for correct equation. We cannot able to write in notes. That is the final equation



So here, with age there can w1 value, with income there can be w2 value and with education there can be w3 value.
With that equation we will get the y.
That y is passed on the sigmoid function to get the result. This is the neuron when there are more features.

In first step, with all feature it will find the y
And then in second step, with y it will find the z on below fomula
z = 1/1+e^-y
z will be between 0 and 1.
This is neuron

Please refer images of this tutorial



-----------------------------------------------------------------------------------------------------------------------------------

Tutorial 4 : Neural Network Simply Explained | Deep Learning Tutorial 4 (Tensorflow2.0, Keras & Python)
------------------------------------------------------------------------------------------------------
Neural network is the combination of multiple neutrons.

Lets talk this with the example to understand neural network
Let say we wanted to build the approach to predict whether the image is koala or not. (Koala is the animal in australia)

To make this happen, we can give split task for each person
Person 1 can take care of eyes
Person 2 can take care of nose
Person 3 can take care of Ears

Person 4 can take care of front legs
Person 5 can take care of back legs

Each persons are assigned with their given parts and we are giving more photos to train on that specific parts.
Once we give the photo to predict, each one will comes up with the score
There is as score of 0 to 1
Which has 0, 0.5 and 1
0 means no, 0.5 not sure. may be. 1 means yes

Person 1, person 2 and person 3 will report the score to Person A (Person A takes care of Face) - There is weightage given for each parts as per importance: Eg: Face = eye * 0.2 + nose * 0.5 + ears * 0.3

Person 4 and person 5 will report the score to Person B (Person B takes care of body) - There is weightage given for this as well: Eg: Body = front leg * 0.5 + back leg * 0.5

Person A and Person B reports to Person C (Person C takes care of final result). There is a weightage here as well Eg: Full koala = face * 0.6 + body * 0.4

Now Person C will give the final score to predict whether it is Koala or not.

This is simple example of neural network.

Here in Neural network it has 3 layers
1. Input layer (Here Person 1, Person 2, Peson 3, Person 4 and Person 5 are input layers)
2. Hidden layer (Person A and Person B are hidden layers)
3. Output layer (Person C is the output layer)


During training, there are changes it might miss predict. During that time, the answer will be given back to correct by themself.
That is Backward error propagation


In neural network there is few elements or set of input layers, there can be multiple set of hidden layers and  there can be few elements or set of output layers.

This is neural network

Refer image for some more details

--------------------------------------------


Tutorial 5 : Install tensorflow 2.0 | Deep Learning Tutorial 5 (Tensorflow Tutorial, Keras & Python)
----------------------------------------------------------------------------------------------------
In this tutorial we can see how we can install tensorflow

Make sure you have only one version of python installed on our machine
If you are install anconda, it will install python first and then it will install anconda.
If there is already a python, then there might be 2 version of python.
This can create a problem.
So better make sure only one python version is installed on your machine
We can go into control panel -> program and features
There we can search for python.

Open terminal or command prompt.
Below is the command to install tensorflow
pip install tensorflow

//This should install tensor flow.

Now if you give below line on jupyter notebook or in python file, we should not get the error
import tensoflow


------------------------------------------


Tutorial 6: Pytorch vs Tensorflow vs Keras | Deep Learning Tutorial 6 (Tensorflow Tutorial, Keras & Python)
--------------------------------------------------------------------------------------------------------
Tensorflow is one of the deep learning framework created by google
Pytorch is other deep learning framework created by facebook
There is one more deep learning frameworkf called CNTK which was created by microsoft. That is not much popular or used like above two.

Keras is not the full fledged deep learning framework.
This is wrapper which internally calls deep learning frameworks like tensorflow, CNTK and Theano

The reason why keras comes is, using tensorflow directly was little code complex.
keras made that simple to use. 

Previously keras will be installed using pip install keras. And the tensorflow will be imported via backend.
Now in tensorflow 2.0 they have included the keras, so we can directly use by calling from tensor import keras. 


----------------------------------------------------------


Tutorial 7: Neural Network For Handwritten Digits Classification | Deep Learning Tutorial 7 (Tensorflow2.0)
----------------------------------------------------------------------------------------------------------

This has little bit of things which covered on tutorial 3 neutron with age factor to determine whether person will buy insurance or not including other featire
Here there can be features like age, education, salary and saving factor.
Here we can pass the age and education to hidden factor awareness
And we can pass salary and saving factor to hidden factor affordable
Now awareness and afforable can pass to output final layer to determine whether person will buy insurance or not
In real time all features will be passed to all hidden layer
Please refer the images

Now lets take the handwritten digits
This we can try to solve with simple neuron which has input layer and output layer.
Later we can add hidden layer to increase the accuracy
As the digit can be one of the digits. 
There are only 10 numbres. So in output layer, we can give 10 neauron.
When image is passed to the input layer and then 10 neurons in the output layer, the matching digit will give the highest score.
Mostly for classification, we can give number of neuron in output layer as per number of different outputs.
Here there is only 10 digit. So we have given 10

We cannot directly give the image file into the input layer.
It accepts only the data.
So the image needs to converted into input data

Here in each image, the background is black and number is drawn in white.
So for black the value can be 0 and for complete white it can be 255.
The image will be splitted into multiple 2D array of boxes or matrix 7 X 7 or might be anything X anything.
Based on whites available on each box, there can be value.
Now we have 2D array (7 X 7) of values.
Now that 2D array of values needs to converted in 1D array with 49 features/columns (7 X 7)
Now these 49 features will be used as the input layer.

In the given digits data set, it has 28 X 28 of 2D values for each image data.
So when converting into single diamension array, it will have 784 features/columns.
We the input layer will have 784 features. And the output layer will have only 10 as the digits are only 10. We can use sigmoid
When an data of one image is passed to this neural network, the predicted value will be shown on one of 10 output layer. That accuracy score will be higher
Eg: when data of image 4 is passed, the 4th neuron of output layer will give highest score.


We can use below which can help many a times

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import pandas as plt
%matplotlib inline
import numpy as np

To load digits use below 

(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()
This will give train and test data set like below

We can check the length like below
len(X_train)

len(X_test)

To see length and number of features in 2D array. 
X_train.shape

To see number only number of features in one of the array
X_train[0].shape

To viwe the data of one of data
X_train[0]

To view the image. Use matplot matshow which show the image as per values in the dataset
plt.matshow(X_train[0])

To view the result value
y_train[0]

First we need to convert into single diamension array of train and test data set. It will be done by reshape in pandas. This called fallen the array
X_train_flatten = X_train.reshape(len(X_train), 28*28)
X_test_flatten = X_test.reshape(len(X_test), 28*28)
Here we have given number of rows and columnds. Rows will take as per length. the columns we have given by passing other 2 array of 28 X 28 = 784
This will create in lenght and 784 columns(features). We have to do the same for train and test data set of X

Now we can view again after reshape via below
X_train_flatten.shape
X_train_flatten[0].shape


Now we need to scale the values. Scalling is optional. But mostly scalling helps on increasing the accuracy. 
We need to make the values from 0 to 1.
We take divide each values with maximum value. That will have make each values from number 0 to 1
Below is the simple way to scale. Here mazimum posible value is 255. So we are dividing by 255
X_train_flatten_scalled = X_train_flatten / 255
X_test_flatten_scalled = X_test_flatten / 255

Now we can cross check the value 
X_train_flatten_scalled[0]


IMPORTANT: use below to create model, configure model, train model and evaluate model

model = keras.Sequential([keras.layers.Dense(10, input_shape=((784,)), activation='sigmoid')])    # Creating the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])     # Configuring the model
model.fit(X_train_flatten_scalled, y_train, epochs=5)               # Training the model
model.evaluate(X_test_flatten_scalled, y_test)                      # Evaluate the model


Below is the explanation:
model = keras.Sequential([keras.layers.Dense(10, input_shape=((784,)), activation='sigmoid')])
This is the place where we will create the model.  keras.layers.Dense(numberOfOutputElement, input_shape=((numberOfInputElement,)), activation='giveActivationFunctionHere')
keras.layers.Dense is used because, we need to map each input elements to each output elements. Dense meaning mapping each input element with each output element
First argument of keras.layers.Dense takes number of output element, next argument takes input share which has number of input element and then the activation 
Above is just the input layer mapped with output layer.
Here there is no hidden layer, we can pass multiple hidden layer as like keras.layers.Dense with different params. We can see that later

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
This complie is used to configure model for training
optimizer is the method of training. Helps to train effectively
There are multiple different loss function. These are used to compare predicted and truth internally and again pass inside for backword propagation error or for resolving
metrics should be accuracy here as we want to create the model with more accurate score.
We can see all the params in details in upcoming tutorials

model.fit(X_train_flatten_scalled, y_train, epochs=5)
This is for training the model with training data set of X and y
Here epochs is the numner of times the model needs to iterate the training samples. Each subset will be divide into training data set as per given epochs number of iteration and train
When training it will give training score. Each epoc training score of training data set which we can see on output when runs

model.evaluate(X_test_flatten_scalled, y_test)
# This is to evaluate score with the test data set.
# For training it uses training data set and shows score in fit. But in evalute this is with test data set and shows the real score which will be used for actual evaluation



We can add the hiddle layer like below when we create the model 
model2 = keras.Sequential([
    keras.layers.Dense(100, input_shape=((784,)), activation='relu'),
    keras.layers.Dense(10, activation='sigmoid')
]
)
Here we have added one hidden layer with 100 neurons to see how it performs. 
Also we have given activation as relu. We will see what is relu in later tutorial. Here in this case, it improved the performance.
Input needs to passed only on first layer


We can avoid flattening manually by callig keras.layers.Flatten to make it one diamension array
model3 = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(100, activation='relu'),
    keras.layers.Dense(10, activation='sigmoid')
]
)
## To flatten we can use  keras.layers.Flatten. This will take care of making to one diamenstion.
## Scalling still we need to take care


Please go through jupyter notebook for more details


---------------------------------------------------------------------------


Tutorial 8: Activation Functions | Deep Learning Tutorial 8 (Tensorflow Tutorial, Keras & Python)
--------------------------------------------------------------------------------------------------
Here we can see how the activation funcations in neural network
Here we can see some of the activation functions

In previous tutorials we have seen now the activation functionals helps to increase the accuracy.
When we have the one of activation functiona like sigmoid function to predict whether the person buy the insurance of not with features like salary, education & age, activation function helps to give the value between 0 to 1. This helps to decide whether the person buy insurance or not based on values. If the value is below 0.5, person may not buy insurance. If value is more than 0.5, person will buy insurance.
Signmoid helps to decide the classification problems.
If there is no sigmoid functinal, value will be minus or plus infinity which is hard to predict the value.
That is the reason we need activation functions

Activation function mostly helps on output layer
Activation function will be used in hidden layer as well


If we remove activation layer from hidden and output layer, the output will be in the linear equation or the straight line.

Previously we have see how the linear function helps to predict the classification with the age factor to decide whether the person will buy insurance.

If we plot the scatter plot of the age and whether the preson buy the insurance or not then we can draw the line to see what splits whether the person buy insurance.
If any of the point goes beyond the limit, then it may not work.
There are chance it might miss classify the results.
That is step function. Step function is the one which gives the answer 0 or 1. Not with any decimals

In step function there are changes it might give 1 for 2 output layer. So we cannot give the correct results.
So it is always better to use sigmoid function which gives in decimals where we can give answers based on maximum values

Sigmoid equation:
signmoid(z) = 1 / 1 + e ^-z

There is another funtion called tanh which gives the value from -1 to 1
tanh equation:
tanh(z) = e^z - e^-z  /  e^z + e^-z

Gentral guidline is to use sigmoid for output layer and try to use tanh for all hidden layer

There is one issue in the sigmoid and tanh layer.
Its in derivatives and loss.
Derivatives gives how much the output changes based on each input.
When value was higher number the derivatives become 0.
This make the learning slower.
This is called vanishing gradients
Sigmoid and Tanh has this vanishing gradients problems. For that reason the learning process become slow

For solving this, we have below functions called ReLu
ReLu
ReLu(z) = max(0, x) 
Here, this this will give 0 if value is 0 or negative value.
And this will give the same number itself if value is any positive value
For hidden layer, if we are not sure which function to use, we can go with ReLu. That should be good
And the learning will be faster here
This is the most popular function. This is very light weight and computation will be faster.
ReLu also has vanishing gradient problem when value goes less than 0.

To solve this, we have one more activation function called Leaky ReLu.
Leaky ReLu(z) = max(0.1x, x)


Below 5 are the all list of activation functions
1. Step function
2. Sigmoid
3. tanh
4. ReLu
5. Leaky ReLu

Some time we need to try and see which function gives the best


Below python code for each function. this is just for our understanding
import math

def sigmoid(x):
  return 1 / (1 + math.exp(-x))
# This gives value between 0 to 1

def tanh(x):
  return (math.exp(x) - math.exp(-x)) / (math.exp(x) + math.exp(-x))
# This gives value between -1 to 1

def relu(x):
  return max(0, x)
# This gives value 0 or the number it self

def leaky_relu(x):
  return max(0.1 * x, x)
# This gives value between of number*0.1 or the number it self

These python code is just for our understanding. But we dont use this directly unless we use custom function.
Mostly we use readymade api or functions which are already available in tensor/keras.

Refer images and jupyter notebook for more details

------------------------------------------------

Tutorial 9: Derivatives | Deep Learning Tutorial 9 (Tensorflow Tutorial, Keras & Python)
----------------------------------------------------------------------------------------





















---------------------------------------------








-------------------------------------------------------------














----------------------------------------------------------------------




----------------------------------------------------------------------------------------
